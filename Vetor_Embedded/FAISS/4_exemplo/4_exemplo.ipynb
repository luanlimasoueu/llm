{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amazon Be\n",
    "import os\n",
    "import boto3\n",
    "from langchain_community.chat_models import BedrockChat\n",
    "from langchain_community.embeddings import BedrockEmbeddings\n",
    "\n",
    "boto3.setup_default_session(\n",
    "    aws_access_key_id = os.getenv(\"aws_access_key_id\"),\n",
    "    aws_secret_access_key= os.getenv(\"aws_secret_access_key\"),\n",
    "    region_name = os.getenv(\"us-east-1\"),\n",
    "    )\n",
    "# Set LLM and embeddings\n",
    "bedrock_runtime = boto3.client(\n",
    "    service_name=\"bedrock-runtime\",\n",
    "    region_name=\"us-east-1\",\n",
    ")\n",
    "\n",
    "model_kwargs =  { \n",
    "    \"temperature\": 0.0,\n",
    "    \"top_k\": 250,\n",
    "    \"top_p\": 1,\n",
    "    \"stop_sequences\": [\"\\n\\nHuman\"],\n",
    "}\n",
    "\n",
    "model_id = \"anthropic.claude-v2\"\n",
    "\n",
    "model = BedrockChat(\n",
    "    client=bedrock_runtime,\n",
    "    model_id=model_id,\n",
    "    model_kwargs=model_kwargs\n",
    ")\n",
    "\n",
    "embeddings = BedrockEmbeddings(\n",
    "    client=bedrock_runtime,\n",
    "    model_id=\"amazon.titan-embed-text-v1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Luan\n",
      "[nltk_data]     Lima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Luan Lima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import UnstructuredURLLoader\n",
    "urls = [\n",
    "    \"https://aws.amazon.com/bedrock/\",\n",
    "    \"https://aws.amazon.com/bedrock/claude/\",\n",
    "    \"https://aws.amazon.com/bedrock/faqs/\",\n",
    "    \"https://aws.amazon.com/bedrock/agents/\",\n",
    "    \"https://aws.amazon.com/bedrock/developer-experience/\",\n",
    "    \"https://aws.amazon.com/bedrock/guardrails/\",\n",
    "    \"https://aws.amazon.com/bedrock/knowledge-bases/\",\n",
    "    \"https://aws.amazon.com/bedrock/security-compliance/\"\n",
    "]\n",
    "loader = UnstructuredURLLoader(urls=urls)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Intelligence›\n",
      "\n",
      "Generative AI›\n",
      "\n",
      "Amazon Bedrock\n",
      "\n",
      "Amazon Bedrock\n",
      "\n",
      "The easiest way to build and scale generative AI applications with foundation models\n",
      "\n",
      "Get started with Amazon Bedrock\n",
      "\n",
      "Try free demo\n",
      "\n",
      "What is Amazon Bedrock?\n",
      "\n",
      "Amazon Bedrock is a fully managed service that offers a choice of high-performing foundation models (FMs) from leading AI companies like AI21 Labs, Anthropic, Cohere, Meta, Mistral AI, Stability AI, and Amazon through a single API, along with a broad set of capabilities you need to build generative AI applications with security, privacy, and responsible AI. Using Amazon Bedrock, you can easily experiment with and evaluate top FMs for your use case, privately customize them with your data using techniques such as fine-tuning and Retrieval Augmented Generation (RAG), and build agents that execute tasks using your enterprise systems and data sources. Since Amazon Bedrock is serverless, you don't have to manage any infrastructure, and you can securely integrate and deploy generative AI capabilities into your applications using the AWS services you are already familiar with.\n",
      "\n",
      "Learn more about Amazon Bedrock developer experience\n",
      "\n",
      "Play\n",
      "\n",
      "How customers are innovating with generative AI on Amazon Bedrock\n",
      "\n",
      "See the full Amazon Bedrock customer stories playlist\n",
      "\n",
      "Play\n",
      "\n",
      "Amazon Bedrock demo\n",
      "\n",
      "Watch this video to see Swami Sivasubramanian, Vice President of Data and AI at AWS, walk through a demo highlighting how you can create new customer experiences using Amazon Bedrock in your organization to build generative AI applications with your data.\n",
      "\n",
      "Play\n",
      "\n",
      "Everything you need to build generative AI applications \n",
      "              \n",
      "              \n",
      "             \n",
      "            \n",
      "           \n",
      "          \n",
      "          \n",
      "           \n",
      "            \n",
      "             \n",
      "              \n",
      "               \n",
      "                \n",
      "                 \n",
      "                  \n",
      "                   \n",
      "                   \n",
      "                   Model choice \n",
      "                   Customization \n",
      "                   RAG \n",
      "                   Agents \n",
      "                   \n",
      "                  \n",
      "                 \n",
      "                \n",
      "               \n",
      "              \n",
      "             \n",
      "             \n",
      "              \n",
      "               \n",
      "                \n",
      "                 \n",
      "                 Choose from a range of leading FMs \n",
      "                  \n",
      "                  Amazon Bedrock helps you rapidly adapt and take advantage of the latest generative AI innovations with easy access to a choice of high-performing FMs from leading AI companies like AI21 Labs, Anthropic, Cohere, Meta, Mistral AI, Stability AI, and Amazon. The single-API access of Amazon Bedrock, regardless of the models you choose, gives you the flexibility to use different FMs and upgrade to the latest model versions with minimal code changes. \n",
      "                  \n",
      "                 \n",
      "                 \n",
      "                 \n",
      "                  \n",
      "                 \n",
      "                \n",
      "               \n",
      "               \n",
      "                \n",
      "                 \n",
      "                 Privately adapt models with your data \n",
      "                  \n",
      "                  Model customization helps you deliver differentiated and personalized user experiences. To customize models for specific tasks, you can privately fine-tune FMs using your own labeled datasets in just a few quick steps. Amazon Bedrock supports fine-tuning for Cohere Command, Meta Llama 2, Amazon Titan Text Lite and Express, Amazon Titan Multimodal Embeddings, and Amazon Titan Image Generator. To adapt Amazon Titan Text models to your industry and domain, you can use continued pretraining with unlabeled data. With fine-tuning and continued pretraining, Amazon Bedrock makes a separate copy of the base FM that is accessible only by you, and your data is not used to train the original base models. \n",
      "                  \n",
      "                  \n",
      "                  Learn more about developer experience \n",
      "                  \n",
      "                 \n",
      "                 \n",
      "                 \n",
      "                  \n",
      "                 \n",
      "                \n",
      "               \n",
      "               \n",
      "                \n",
      "                 \n",
      "                 Deliver more relevant FM responses \n",
      "                  \n",
      "                  To equip the FM with up-to-date proprietary information, organizations use RAG, a technique that involves fetching data from company data sources and enriching the prompt with that data to deliver more relevant and accurate responses. Knowledge Bases for Amazon Bedrock is a fully managed RAG capability that allows you to customize FM responses with contextual and relevant company data. Knowledge Bases for Amazon Bedrock automates the complete RAG workflow, including ingestion, retrieval, prompt augmentation, and citations, removing the need for you to write custom code to integrate data sources and manage queries. \n",
      "                  \n",
      "                  \n",
      "                  Learn about Knowledge Bases for Amazon Bedrock \n",
      "                  \n",
      "                 \n",
      "                 \n",
      "                 \n",
      "                  \n",
      "                 \n",
      "                \n",
      "               \n",
      "               \n",
      "                \n",
      "                 \n",
      "                 Execute complex tasks across company systems \n",
      "                  \n",
      "                  Agents for Amazon Bedrock plan and execute multistep tasks using company systems and data sources—from answering customer questions about your product availability to taking their orders. With Amazon Bedrock, you can create an agent in just a few quick steps by first selecting an FM and providing it access to your enterprise systems, knowledge bases, and AWS Lambda functions to securely execute your APIs. An agent analyzes the user request and automatically calls the necessary APIs and data sources to fulfill the request. Agents for Amazon Bedrock offer enhanced security and privacy—no need for you to engineer prompts, manage session context, or manually orchestrate tasks. \n",
      "                  \n",
      "                  \n",
      "                  Learn about Agents for Amazon Bedrock\n",
      "\n",
      "Security, privacy, and safety \n",
      "              \n",
      "              \n",
      "             \n",
      "            \n",
      "           \n",
      "          \n",
      "          \n",
      "           \n",
      "            \n",
      "             \n",
      "              \n",
      "               \n",
      "                \n",
      "                Features page \n",
      "                \n",
      "                \n",
      "                Security and privacy for your data and applications \n",
      "                 \n",
      "                 Explore security and privacy features \n",
      "                  \n",
      "                    \n",
      "                     \n",
      "                    \n",
      "                 \n",
      "                \n",
      "               \n",
      "              \n",
      "              \n",
      "               \n",
      "              \n",
      "             \n",
      "           \n",
      "           \n",
      "            \n",
      "             \n",
      "              \n",
      "               \n",
      "                \n",
      "                Features page \n",
      "                \n",
      "                \n",
      "                Guardrails to build generative AI apps safely and responsibly \n",
      "                 \n",
      "                 Explore Guardrails for Amazon Bedrock\n",
      "\n",
      "Broad choice of models from leading AI companies \n",
      "           \n",
      "           \n",
      "            \n",
      "             \n",
      "             AI21 Labs \n",
      "            Instruction-following FMs built for the enterprise that perform a range of tasks including text generation, question answering, summarization, and more. \n",
      "             \n",
      "             Learn more \n",
      "              \n",
      "                \n",
      "                 \n",
      "                \n",
      "             \n",
      "           \n",
      "           \n",
      "            \n",
      "             \n",
      "             Amazon \n",
      "            A family of FMs for text and image generation, summarization, classification, open-ended Q&A, information extraction, and text or image search. \n",
      "             \n",
      "             Learn more \n",
      "              \n",
      "                \n",
      "                 \n",
      "                \n",
      "             \n",
      "           \n",
      "           \n",
      "            \n",
      "             \n",
      "             Anthropic \n",
      "            FMs for thoughtful dialogue, content creation, complex reasoning, creative writing, and coding, trained with Constitutional AI. \n",
      "             \n",
      "             Learn more \n",
      "              \n",
      "                \n",
      "                 \n",
      "                \n",
      "             \n",
      "           \n",
      "           \n",
      "            \n",
      "             \n",
      "             Cohere \n",
      "            Text-generation and representation models to generate text, summarize, search, cluster, classify, and use RAG. \n",
      "             \n",
      "             Learn more \n",
      "              \n",
      "                \n",
      "                 \n",
      "                \n",
      "             \n",
      "           \n",
      "           \n",
      "            \n",
      "             \n",
      "             Meta \n",
      "            Models ideal for dialogue use cases and natural language tasks like Q&A and reading comprehension. \n",
      "             \n",
      "             Learn more \n",
      "              \n",
      "                \n",
      "                 \n",
      "                \n",
      "             \n",
      "           \n",
      "           \n",
      "            \n",
      "             \n",
      "             Mistral AI \n",
      "            Models with publicly available weights supporting a variety of use cases from text summarization, text classification, and text completion to code generation and code completion. \n",
      "             \n",
      "             Learn More \n",
      "              \n",
      "                \n",
      "                 \n",
      "                \n",
      "             \n",
      "           \n",
      "           \n",
      "            \n",
      "             \n",
      "             Stability AI \n",
      "            Image-generation models that produce unique, realistic, and high-quality visuals, art, logos, and designs. \n",
      "             \n",
      "             Learn more\n",
      "\n",
      "Use cases \n",
      "            \n",
      "           \n",
      "           \n",
      "           \n",
      "            \n",
      "             \n",
      "             Text generation \n",
      "              \n",
      "               \n",
      "                \n",
      "                 \n",
      "                \n",
      "              \n",
      "             \n",
      "             \n",
      "              \n",
      "              Create new pieces of original content, such as blog posts, social media posts, and webpage copy. \n",
      "              \n",
      "             \n",
      "            \n",
      "            \n",
      "             \n",
      "             Virtual assistants \n",
      "              \n",
      "               \n",
      "                \n",
      "                 \n",
      "                \n",
      "              \n",
      "             \n",
      "             \n",
      "              \n",
      "              Build assistants that understand user requests, automatically break down tasks, engage in dialogue to collect information, and take actions to fulfill the request. \n",
      "              \n",
      "             \n",
      "            \n",
      "            \n",
      "             \n",
      "             Text and image search \n",
      "              \n",
      "               \n",
      "                \n",
      "                 \n",
      "                \n",
      "              \n",
      "             \n",
      "             \n",
      "              \n",
      "              Search and synthesize relevant information to answer questions and provide recommendations from a large corpus of text and image data. \n",
      "              \n",
      "             \n",
      "            \n",
      "            \n",
      "             \n",
      "             Text summarization \n",
      "              \n",
      "               \n",
      "                \n",
      "                 \n",
      "                \n",
      "              \n",
      "             \n",
      "             \n",
      "              \n",
      "              Get concise summaries of long documents such as articles, reports, research papers, technical documentation, and even books to quickly and effectively extract important information. \n",
      "              \n",
      "             \n",
      "            \n",
      "            \n",
      "             \n",
      "             Image generation \n",
      "              \n",
      "               \n",
      "                \n",
      "                 \n",
      "                \n",
      "              \n",
      "             \n",
      "             \n",
      "              \n",
      "              Quickly create realistic and visually appealing images for ad campaigns, websites, presentations, and more.\n",
      "\n",
      "How to get started \n",
      "              \n",
      "              \n",
      "             \n",
      "            \n",
      "           \n",
      "          \n",
      "          \n",
      "           \n",
      "            \n",
      "             \n",
      "              \n",
      "               \n",
      "               Blog \n",
      "               \n",
      "               \n",
      "               New capabilities make it easier to use Amazon Bedrock to build and scale generative AI applications and deliver impact \n",
      "                \n",
      "                Read the blog \n",
      "                 \n",
      "                   \n",
      "                    \n",
      "                   \n",
      "                \n",
      "               \n",
      "              \n",
      "             \n",
      "           \n",
      "           \n",
      "            \n",
      "             \n",
      "              \n",
      "               \n",
      "               Training \n",
      "               \n",
      "               \n",
      "               Learn how to build generative AI apps using Amazon Bedrock \n",
      "                \n",
      "                Take the training \n",
      "                 \n",
      "                   \n",
      "                    \n",
      "                   \n",
      "                \n",
      "               \n",
      "              \n",
      "             \n",
      "           \n",
      "           \n",
      "            \n",
      "             \n",
      "              \n",
      "               \n",
      "               Tutorial \n",
      "               \n",
      "               \n",
      "               Explore common generative AI use cases with Amazon Bedrock Workshop \n",
      "                \n",
      "                Gain hands-on experience\n",
      "{'source': 'https://aws.amazon.com/bedrock/'}\n",
      "Generative AI›\n",
      "\n",
      "Amazon Bedrock›\n",
      "\n",
      "Claude\n",
      "\n",
      "Anthropic's Claude in Amazon Bedrock\n",
      "\n",
      "Build generative AI solutions with Anthropic’s state-of-the-art model, Claude\n",
      "\n",
      "Get started with Claude in Amazon Bedrock\n",
      "\n",
      "Introducing the latest Claude models \n",
      "            Choose the exact combination of intelligence, speed, and cost to suit your needs. All of the latest Claude models are available now in Amazon Bedrock. \n",
      "            \n",
      "           \n",
      "           \n",
      "           \n",
      "            \n",
      "             \n",
      "             Claude 3.5 Sonnet \n",
      "              \n",
      "               \n",
      "                \n",
      "                 \n",
      "                \n",
      "              \n",
      "             \n",
      "             \n",
      "             \n",
      "               Anthropic’s most intelligent and advanced model, Claude 3.5 Sonnet, demonstrates exceptional capabilities across a diverse range of tasks and evaluations while also outperforming Claude 3 Opus. \n",
      "              \n",
      "             \n",
      "            \n",
      "            \n",
      "             \n",
      "             Claude 3 Opus \n",
      "              \n",
      "               \n",
      "                \n",
      "                 \n",
      "                \n",
      "              \n",
      "             \n",
      "             \n",
      "             \n",
      "               Opus is a highly intelligent model with reliable performance on complex tasks. It can navigate open-ended prompts and sight-unseen scenarios with remarkable fluency and human-like understanding. Use Opus to automate tasks, and accelerate research and development across a diverse range of use cases and industries. \n",
      "              \n",
      "             \n",
      "            \n",
      "            \n",
      "             \n",
      "             Claude 3 Haiku \n",
      "              \n",
      "               \n",
      "                \n",
      "                 \n",
      "                \n",
      "              \n",
      "             \n",
      "             \n",
      "             \n",
      "               Haiku is Anthropic’s fastest, most compact model for near-instant responsiveness. Haiku is the best choice for building seamless AI experiences that mimic human interactions. Enterprises can use Haiku to moderate content, optimize inventory management, produce quick and accurate translations, summarize unstructured data, and more.\n",
      "\n",
      "Trustworthy AI Systems\n",
      "\n",
      "Anthropic was founded to create the world’s safest and most capable large language model. Claude is Anthropic’s frontier, state-of-the-art large language models that offers important features for enterprises like advanced reasoning, vision analysis, code generation, and multilingual processing. Hear from Neerav Kingsland, Head of Global Accounts at Anthropic, as he discusses what Claude’s availability in Amazon Bedrock can provide for businesses around the world.\n",
      "\n",
      "Benefits \n",
      "            \n",
      "           \n",
      "           \n",
      "           \n",
      "            \n",
      "             \n",
      "             200K token context window \n",
      "              \n",
      "               \n",
      "                \n",
      "                 \n",
      "                \n",
      "              \n",
      "             \n",
      "             \n",
      "             \n",
      "               Anthropic's Claude models have a 200,000 token context window enabling you to relay a large volume of information to Claude. This translates to roughly 150,000 words, or over 500 pages of material. You can now upload technical documentation like entire codebases, financial statements, or even long literary works. By being able to talk to large bodies of content or data, Claude can summarize, perform Q&A, forecast trends, compare and contrast multiple documents, and much more. \n",
      "              \n",
      "             \n",
      "            \n",
      "            \n",
      "             \n",
      "             Intelligence \n",
      "              \n",
      "               \n",
      "                \n",
      "                 \n",
      "                \n",
      "              \n",
      "             \n",
      "             \n",
      "             \n",
      "               Claude 3.5 Sonnet exhibits near-human levels of comprehension and fluency on complex tasks, leading the frontier of general intelligence. Claude can be used for sophisticated dialogue, nuanced creative content generation, complex reasoning, math, coding, and scientific queries. It can edit, rewrite, summarize, classify, extract structured data, perform Q&A based on provided content, and more. Claude models offer increased steerability, giving users more control, and produce predictable, high-quality outputs. In practical business scenarios, Claude 3.5 Sonnet can help financial analysts analyze complex financial reports, identify key trends, and generate insightful summaries for stakeholders. Marketing teams can leverage Claude's exceptional writing skills to craft compelling ad copy, product descriptions, and social media content that resonates with target audiences. Healthcare professionals can employ Claude to quickly summarize patient records, identify potential drug interactions, and assist in diagnostic processes. Legal firms can use Claude to efficiently review and summarize lengthy legal documents, identify relevant precedents, and draft initial contract templates. \n",
      "              \n",
      "             \n",
      "            \n",
      "            \n",
      "             \n",
      "             Vision \n",
      "              \n",
      "               \n",
      "                \n",
      "                 \n",
      "                \n",
      "              \n",
      "             \n",
      "             \n",
      "             \n",
      "               Claude 3.5 Sonnet offers best-in-class vision capabilities compared to other leading models. It can accurately transcribe text from imperfect images—a core capability for retail, logistics, and financial services, where AI may glean more insights from an image, graphic, or illustration than from text alone. The latest Claude models demonstrate a strong aptitude for understanding a wide range of visual formats, including photos, charts, graphs and technical diagrams. With Claude, you can extract more insights from documents, process web UI and diverse product documentation, generate image catalog metadata, and more. \n",
      "              \n",
      "             \n",
      "            \n",
      "            \n",
      "             \n",
      "             Speed \n",
      "              \n",
      "               \n",
      "                \n",
      "                 \n",
      "                \n",
      "              \n",
      "             \n",
      "             \n",
      "             \n",
      "               Claude 3 Haiku is fast and cost-effective for its intelligence category. Claude 3 models excel at complex tasks demanding rapid responses, like knowledge retrieval or sales automation. \n",
      "              \n",
      "             \n",
      "            \n",
      "            \n",
      "             \n",
      "             Frontier AI safety features \n",
      "              \n",
      "               \n",
      "                \n",
      "                 \n",
      "                \n",
      "              \n",
      "             \n",
      "             \n",
      "             \n",
      "               Claude is based on Anthropic’s leading safety research, and built with techniques including Constitutional AI. With industry-leading resistance to jailbreaks and misuse, Claude is designed to reduce brand risk, and aims to be helpful, honest, and harmless.\n",
      "\n",
      "Amazon and Anthropic strategic collaboration\n",
      "\n",
      "In this fireside chat, Dario Amodei, CEO and co-founder of Anthropic, and Adam Selipsky, CEO of AWS, discuss Claude and how Anthropic and AWS are working together to accelerate the responsible deployment of generative AI.\n",
      "\n",
      "Meet Claude, Anthropic's large language model\n",
      "\n",
      "Claude is based on Anthropic’s research into creating reliable, interpretable, and steerable AI systems. Created using techniques like Constitutional AI and harmlessness training, Claude excels at thoughtful dialogue, content creation, complex reasoning, creativity, and coding.\n",
      "\n",
      "Prompt engineering best practices from Anthropic\n",
      "\n",
      "Prompt engineering is the process of guiding LLMs to produce desired outputs. Get an overview of prompt engineering best practices and learn how to choose the most appropriate formats, phrases, words, and symbols to get the most out of generative AI solutions while improving accuracy and performance. This session uses Anthropic's Claude LLM as an example of how prompt engineering helps to solve complex customer use cases. Also learn how prompts can be integrated with your architecture and how to use API parameters for tuning the model parameters using Amazon Bedrock.\n",
      "\n",
      "Use cases \n",
      "            \n",
      "           \n",
      "           \n",
      "           \n",
      "            \n",
      "             \n",
      "             Customer service \n",
      "              \n",
      "               \n",
      "                \n",
      "                 \n",
      "                \n",
      "              \n",
      "             \n",
      "             \n",
      "              \n",
      "              Claude can act as an always-on virtual sales representative, ensure speedy and friendly resolution to service requests, and increase customer satisfaction. \n",
      "              \n",
      "             \n",
      "            \n",
      "            \n",
      "             \n",
      "             Operations \n",
      "              \n",
      "               \n",
      "                \n",
      "                 \n",
      "                \n",
      "              \n",
      "             \n",
      "             \n",
      "              \n",
      "              Claude can extract relevant information from business emails and documents, categorize and summarize survey responses, and wrangle reams of text with high speed and accuracy. \n",
      "              \n",
      "             \n",
      "            \n",
      "            \n",
      "             \n",
      "             Legal \n",
      "              \n",
      "               \n",
      "                \n",
      "                 \n",
      "                \n",
      "              \n",
      "             \n",
      "             \n",
      "              \n",
      "              Claude is able to parse legal documents and answer questions about them, so lawyers can reduce costs and focus on higher-level work. \n",
      "              \n",
      "             \n",
      "            \n",
      "            \n",
      "             \n",
      "             Insurance \n",
      "              \n",
      "               \n",
      "                \n",
      "                 \n",
      "                \n",
      "              \n",
      "             \n",
      "             \n",
      "              \n",
      "              Claude can help insurance agents make faster, better claims decisions by providing insights across customer conversations, claims documents, and policies. \n",
      "              \n",
      "             \n",
      "            \n",
      "            \n",
      "             \n",
      "             Coding \n",
      "              \n",
      "               \n",
      "                \n",
      "                 \n",
      "                \n",
      "              \n",
      "             \n",
      "             \n",
      "              \n",
      "              Claude can help boost developer productivity by assisting with in-line code generation, debugging, and having natural-language conversation to help developers understand existing code.\n",
      "\n",
      "Model versions\n",
      "\n",
      "Claude 3.5 Sonnet\n",
      "\n",
      "Anthropic’s most intelligent and advanced model, Claude 3.5 Sonnet, demonstrates exceptional capabilities across a diverse range of tasks and evaluations while also outperforming Claude 3 Opus.\n",
      "\n",
      "Max Tokens: 200K\n",
      "\n",
      "Languages: English, Spanish, Japanese, and multiple other languages.\n",
      "\n",
      "Supported Use Cases: RAG or search & retrieval over vast amounts of knowledge, product recommendations, forecasting, targeted marketing, code generation, quality control, parse text from images.\n",
      "\n",
      "Read the blog\n",
      "\n",
      "Claude 3 Opus\n",
      "\n",
      "Claude 3 Opus is a powerful and reliable AI model, with top-level performance on highly complex tasks. It can navigate open-ended prompts and sight-unseen scenarios with remarkable fluency and human-like understanding.\n",
      "\n",
      "Max Tokens: 200K\n",
      "\n",
      "Languages: English, Spanish, Japanese, and multiple other languages.\n",
      "\n",
      "Supported Use Cases: Task automation, interactive coding, research review, brainstorming and hypothesis generation, advanced analysis of charts & graphs, financials and market trends, forecasting.\n",
      "\n",
      "Read the blog\n",
      "\n",
      "Claude 3 Haiku\n",
      "\n",
      "Anthropic’s fastest, most compact model for near-instant responsiveness. It answers simple queries and requests with speed.\n",
      "\n",
      "Max tokens: 200K\n",
      "\n",
      "Languages: English, Spanish, Japanese, and multiple other languages.\n",
      "\n",
      "Supported use cases: Quick and accurate support in live interactions, translations, content moderation, optimize logistics, inventory management, extract knowledge from unstructured data.\n",
      "\n",
      "Read the blog\n",
      "\n",
      "Claude 3 Sonnet\n",
      "\n",
      "Claude 3 Sonnet is engineered to be dependable for scaled AI deployments across a variety of use cases.\n",
      "\n",
      "Max tokens: 200K\n",
      "\n",
      "Languages: English, Spanish, Japanese, and multiple other languages.\n",
      "\n",
      "Supported use cases: RAG or search & retrieval over vast amounts of knowledge, product recommendations, forecasting, targeted marketing, code generation, quality control, parse text from images.\n",
      "\n",
      "Read the blog\n",
      "\n",
      "Claude 2.1\n",
      "\n",
      "Claude 2.1 is a large language model (LLM) by Anthropic with a 200K token context window, reduced hallucination rates, and improved accuracy over long documents.\n",
      "\n",
      "Max tokens: 200K\n",
      "\n",
      "Languages: English and multiple other languages\n",
      "\n",
      "Supported use cases: Summarization, Q&A, trend forecasting, comparing and contrasting multiple documents, and analysis. Claude 2.1 excels at the core capabilities of Claude 2.0 and Claude Instant.\n",
      "\n",
      "Read the blog\n",
      "\n",
      "Claude 2.0\n",
      "\n",
      "Claude 2.0 is a leading LLM from Anthropic that enables a wide range of tasks from sophisticated dialogue and creative content generation to detailed instruction.\n",
      "\n",
      "Max tokens: 100K\n",
      "\n",
      "Languages: English and multiple other languages\n",
      "\n",
      "Supported use cases: Thoughtful dialogue, content creation, complex reasoning, creativity, and coding.\n",
      "\n",
      "Claude Instant\n",
      "\n",
      "Claude Instant is Anthropic's faster, lower-priced yet very capable LLM.\n",
      "\n",
      "Max tokens: 100K\n",
      "\n",
      "Languages: English and multiple other languages\n",
      "\n",
      "Supported use cases: Casual dialogue, text analysis, summarization, and document comprehension.\n",
      "\n",
      "How to get started \n",
      "              \n",
      "              \n",
      "             \n",
      "            \n",
      "           \n",
      "          \n",
      "          \n",
      "           \n",
      "            \n",
      "             \n",
      "              \n",
      "               \n",
      "               \n",
      "               Claude 3.5 Sonnet is now available in Amazon Bedrock \n",
      "                \n",
      "                Read the blog \n",
      "                 \n",
      "                   \n",
      "                    \n",
      "                   \n",
      "                \n",
      "               \n",
      "              \n",
      "             \n",
      "           \n",
      "           \n",
      "            \n",
      "             \n",
      "              \n",
      "               \n",
      "               Blog \n",
      "               \n",
      "               \n",
      "               Claude 3 Opus is now available in Amazon Bedrock \n",
      "                \n",
      "                Read the blog \n",
      "                 \n",
      "                   \n",
      "                    \n",
      "                   \n",
      "                \n",
      "               \n",
      "              \n",
      "             \n",
      "           \n",
      "           \n",
      "            \n",
      "             \n",
      "              \n",
      "               \n",
      "               Blog \n",
      "               \n",
      "               \n",
      "               Claude 3 Sonnet is now available in Amazon Bedrock \n",
      "                \n",
      "                Read the blog \n",
      "                 \n",
      "                   \n",
      "                    \n",
      "                   \n",
      "                \n",
      "               \n",
      "              \n",
      "             \n",
      "           \n",
      "           \n",
      "            \n",
      "             \n",
      "              \n",
      "               \n",
      "               Blog \n",
      "               \n",
      "               \n",
      "               Claude 3 Haiku is now available in Amazon Bedrock \n",
      "                \n",
      "                Read the blog\n",
      "{'source': 'https://aws.amazon.com/bedrock/claude/'}\n",
      "Generative AI›\n",
      "\n",
      "Amazon Bedrock›\n",
      "\n",
      "FAQs\n",
      "\n",
      "Amazon Bedrock FAQs\n",
      "\n",
      "Page Topics\n",
      "\n",
      "General \n",
      "            \n",
      "              10\n",
      "\n",
      "Agents \n",
      "            \n",
      "              4\n",
      "\n",
      "Security \n",
      "            \n",
      "              4\n",
      "\n",
      "SDK \n",
      "            \n",
      "              2\n",
      "\n",
      "Billing and support \n",
      "            \n",
      "              3\n",
      "\n",
      "Customization \n",
      "            \n",
      "              6\n",
      "\n",
      "Amazon Titan \n",
      "            \n",
      "              2\n",
      "\n",
      "Retrieval augmented generation (RAG) \n",
      "            \n",
      "              5\n",
      "\n",
      "Model evaluation \n",
      "            \n",
      "              5\n",
      "\n",
      "Responsible AI \n",
      "            \n",
      "              4\n",
      "\n",
      "General\n",
      "\n",
      "General\n",
      "\n",
      "What is Amazon Bedrock?\n",
      "\n",
      "Amazon Bedrock is a fully managed service that offers a choice of high-performing foundation models (FMs) along with a broad set of capabilities that you need to build generative AI applications, simplifying development with security, privacy, and responsible AI. With the comprehensive capabilities of Amazon Bedrock, you can experiment with a variety of top FMs, customize them privately with your data using techniques such as fine-tuning and retrieval-augmented generation (RAG), and create managed agents that execute complex business tasks—from booking travel and processing insurance claims to creating ad campaigns and managing inventory—all without writing any code. Since Amazon Bedrock is serverless, you don't have to manage any infrastructure, and you can securely integrate and deploy generative AI capabilities into your applications using the AWS services you are already familiar with.\n",
      "\n",
      "Which FMs are available on Amazon Bedrock?\n",
      "\n",
      "Amazon Bedrock customers can choose from some of the most cutting-edge FMs available today. This includes Anthropic's Claude, AI21 Labs' Jurassic-2, Stability AI's Stable Diffusion, Cohere's Command and Embed, Meta's Llama 2, and the Amazon Titan language and embeddings models.\n",
      "\n",
      "Why should I use Amazon Bedrock?\n",
      "\n",
      "There are five reasons to use Amazon Bedrock for building generative AI applications.\n",
      "\n",
      "Choice of leading FMs: Amazon Bedrock offers an easy-to-use developer experience to work with a broad range of high-performing FMs from Amazon and leading AI companies like AI21 Labs, Anthropic, Cohere, Meta, and Stability AI. You can quickly experiment with a variety of FMs in the playground, and use a single API for inference regardless of the models you choose, giving you the flexibility to use FMs from different providers and keep up to date with the latest model versions with minimal code changes.\n",
      "\n",
      "Easy model customization with your data: Privately customize FMs with your own data through a visual interface without writing any code. Simply select the training and validation data sets stored in Amazon Simple Storage Service (Amazon S3) and, if required, adjust the hyperparameters to achieve the best possible model performance.\n",
      "\n",
      "Fully managed agents that can invoke APIs dynamically to execute tasks: Build agents that execute complex business tasks—from booking travel and processing insurance claims to creating ad campaigns, preparing tax filings, and managing your inventory—by dynamically calling your company systems and APIs. Fully managed agents for Amazon Bedrock extend the reasoning capabilities of FMs to break down tasks, create an orchestration plan, and execute it.\n",
      "\n",
      "Native support for RAG to extend the power of FMs with proprietary data: With Knowledge Bases for Amazon Bedrock, you can securely connect FMs to your data sources for retrieval augmentation—from within the managed service—extending the FM’s already powerful capabilities and making it more knowledgeable about your specific domain and organization.\n",
      "\n",
      "Data security and compliance certifications: Amazon Bedrock offers several capabilities to support security and privacy requirements. Amazon Bedrock is in scope for common compliance standards such as Service and Organization Control (SOC), International Organization for Standardization (ISO), is Health Insurance Portability and Accountability Act (HIPAA) eligible, and customers can use Amazon Bedrock in compliance with the General Data Protection Regulation (GDPR). Amazon Bedrock is CSA Security Trust Assurance and Risk (STAR) Level 2 certified, which validates the use of best practices and the security posture of AWS cloud offerings. With Amazon Bedrock, your content is not used to improve the base models and is not shared with any model providers. Your data in Amazon Bedrock is always encrypted in transit and at rest, and you can optionally encrypt the data using your own keys. You can use AWS PrivateLink with Amazon Bedrock to establish private connectivity between your FMs and your Amazon Virtual Private Cloud (Amazon VPC) without exposing your traffic to the Internet.\n",
      "\n",
      "How can I get started with Amazon Bedrock?\n",
      "\n",
      "With the serverless experience of Amazon Bedrock, you can quickly get started. Navigate to Amazon Bedrock in the AWS Management Console and try out the FMs in the playground. You can also create an agent and test it in the console. Once you’ve identified your use case, you can easily integrate the FMs into your applications using AWS tools without having to manage any infrastructure.\n",
      "\n",
      "How does Amazon Bedrock work with other services?\n",
      "\n",
      "Amazon Bedrock works with AWS Lambda for invoking actions, Amazon S3 for training and validation data, and Amazon CloudWatch for tracking metrics.\n",
      "\n",
      "What are the most common use cases for Amazon Bedrock?\n",
      "\n",
      "You can quickly get started with use cases:\n",
      "\n",
      "Create new pieces of original content, such as short stories, essays, social media posts, and web page copy.\n",
      "\n",
      "Search, find, and synthesize information to answer questions from a large corpus of data.\n",
      "\n",
      "Create realistic and artistic images of various subjects, environments, and scenes from language prompts.\n",
      "\n",
      "Help customers find what they’re looking for with more relevant and contextual product recommendations than word matching.\n",
      "\n",
      "Get a summary of textual content such as articles, blog posts, books, and documents to get the gist without having to read the full content.\n",
      "\n",
      "Explore more generative AI use cases.\n",
      "\n",
      "What is Amazon Bedrock Chat Playground?\n",
      "\n",
      "Amazon Bedrock offers a playground that allows you to experiment with various FMs using a conversational chat interface. You can provide a prompt and use a web interface inside the console to supply a prompt and use the pretrained models to generate text or images, or alternatively use a fine-tuned model that has been adapted for your use case.\n",
      "\n",
      "In which AWS Regions is Amazon Bedrock available?\n",
      "\n",
      "For a list of AWS Regions where Amazon Bedrock is available, see Amazon Bedrock endpoints and quotas in the Amazon Bedrock Reference Guide.\n",
      "\n",
      "How do I customize a model on Amazon Bedrock?\n",
      "\n",
      "You can easily fine-tune FMs on Amazon Bedrock. To get started, provide the training and validation dataset, configure hyperparameters (epochs, batch size, learning rate, warmup steps) and submit the job. Within a couple of hours, your fine-tuned model can be accessed with the same API (InvokeModel).\n",
      "\n",
      "Can I train a model and deploy it on Amazon Bedrock?\n",
      "\n",
      "Amazon Bedrock is a managed service that you can use to access FMs. You can fine-tune a model and use it with the Amazon Bedrock API.\n",
      "\n",
      "Agents\n",
      "\n",
      "What are Agents for Amazon Bedrock?\n",
      "\n",
      "Agents for Amazon Bedrock are fully managed capabilities that make it easier for developers to create generative AI–based applications that can complete complex tasks for a wide range of use cases and deliver up-to-date answers based on proprietary knowledge sources. In just a few short steps, Agents for Amazon Bedrock automatically break down tasks and create an orchestration plan–without any manual coding. The agent securely connects to company data through an API, automatically converting data into a machine-readable format, and augmenting the request with relevant information to generate the most accurate response. Agents can then automatically call APIs to fulfill a user’s request. For example, a manufacturing company might want to develop a generative AI application that automates tracking inventory levels, sales data, supply chain information and that can recommend optimal reorder points and quantities to maximize efficiency. As fully managed capabilities, Agents for Amazon Bedrock remove the undifferentiated lifting of managing system integration and infrastructure provisioning, allowing developers to use generative AI to its full extent throughout their organization.\n",
      "\n",
      "How can I connect FMs to my company data sources?\n",
      "\n",
      "You can securely connect FMs to your company data sources using Agents for Amazon Bedrock. With a knowledge base, you can use agents to give FMs in Amazon Bedrock access to additional data that helps the model generate more relevant, context-specific, and accurate responses without continually retraining the FM. Based on user input, agents identify the appropriate knowledge base, retrieve the relevant information, and add the information to the input prompt, giving the model more context information to generate a completion.\n",
      "\n",
      "What are some use cases for Agents for Amazon Bedrock?\n",
      "\n",
      "Agents for Amazon Bedrock can help you increase productivity, improve your customer service experience, or automate DevOps tasks.\n",
      "\n",
      "How do Agents for Amazon Bedrock help improve developer productivity?\n",
      "\n",
      "With agents, developers have seamless support for monitoring, encryption, user permissions, and API invocation management without writing custom code. Agents for Amazon Bedrock automate the prompt engineering and orchestration of user-requested tasks. Developers can use the agent-created prompt template as a baseline to further refine it for an enhanced user experience. They can update the user input, orchestration plan, and the FM response. With access to the prompt template developers have better control over the Agent orchestration.\n",
      "\n",
      "With fully managed agents, you don’t have to worry about provisioning or managing infrastructure and can take applications to production faster.\n",
      "\n",
      "Security\n",
      "\n",
      "Is the content processed by Amazon Bedrock moved outside the AWS Region where I am using Amazon Bedrock?\n",
      "\n",
      "Any customer content processed by Amazon Bedrock is encrypted and stored at rest in the AWS Region where you are using Amazon Bedrock.\n",
      "\n",
      "Are user inputs and model outputs made available to third-party model providers?\n",
      "\n",
      "No. Users' inputs and model outputs are not shared with any model providers.\n",
      "\n",
      "What security and compliance standards does Amazon Bedrock support?\n",
      "\n",
      "Amazon Bedrock offers several capabilities to support security and privacy requirements. Bedrock is in scope for common compliance standards such as Service and Organization Control (SOC), International Organization for Standardization (ISO), Health Insurance Portability and Accountability Act (HIPAA) eligibility, and customers can use Bedrock in compliance with the General Data Protection Regulation (GDPR). Amazon Bedrock is included in the scope of the SOC 1, 2, 3 reports, allowing customers to gain insights into our security controls. We demonstrate compliance through extensive third-party audits of our AWS controls. Amazon Bedrock is one of the AWS services under ISO Compliance for the ISO 9001, ISO 27001, ISO 27017, ISO 27018, ISO 27701, ISO 22301, and ISO 20000 standards. Amazon Bedrock is CSA Security Trust Assurance and Risk (STAR) Level 2 certified, which validates the use of best practices and the security posture of AWS cloud offerings. With Amazon Bedrock, your content is not used to improve the base models and is not shared with any model providers. You can use AWS PrivateLink to establish private connectivity from Amazon VPC to Amazon Bedrock, without having to expose your data to internet traffic.\n",
      "\n",
      "Will AWS and third-party model providers use customer inputs to or outputs from Amazon Bedrock to train Amazon Titan or any third-party models?\n",
      "\n",
      "No, AWS and the third-party model providers will not use any inputs to or outputs from Amazon Bedrock to train Amazon Titan or any third-party models.\n",
      "\n",
      "SDK\n",
      "\n",
      "What SDKs are supported for Amazon Bedrock?\n",
      "\n",
      "Amazon Bedrock supports SDKs for runtime services. iOS and Android SDKs, as well as Java, JS, Python, CLI, .Net, Ruby, PHP, Go, and C++, support both text and speech input.\n",
      "\n",
      "What SDKs support streaming functionality?\n",
      "\n",
      "Streaming is supported on all the SDKs.\n",
      "\n",
      "Billing and support\n",
      "\n",
      "How much does Amazon Bedrock cost?\n",
      "\n",
      "See Amazon Bedrock pricing for current pricing information.\n",
      "\n",
      "What support is provided for Amazon Bedrock?\n",
      "\n",
      "Depending on your AWS Support contract, Amazon Bedrock is supported under Developer Support, Business Support and Enterprise Support plans.\n",
      "\n",
      "How can I track the input and output tokens?\n",
      "\n",
      "You can use CloudWatch metrics to track the inputs and output token.\n",
      "\n",
      "Customization\n",
      "\n",
      "How can I securely use my data to customize FMs available through Amazon Bedrock?\n",
      "\n",
      "With Amazon Bedrock, you can privately customize FMs, retaining control over how your data is used and encrypted. Amazon Bedrock makes a separate copy of the base FM and trains this private copy of the model. Your data including prompts, information used to supplement a prompt, and FM responses. Customized FMs remain in the Region where the API call is processed.\n",
      "\n",
      "How does Amazon Bedrock ensure my data used in fine-tuning remains private and confidential?\n",
      "\n",
      "When you’re fine-tuning a model, your data is never exposed to the public internet, never leaves the AWS network, is securely transferred through your VPC, and is encrypted in transit and at rest. Amazon Bedrock also enforces the same AWS access controls that you have with any of our other services.\n",
      "\n",
      "Does Amazon Bedrock support continued pretraining?\n",
      "\n",
      "We launched continued pretraining for Amazon Titan Text Express and Amazon Titan models on Amazon Bedrock. Continued pretraining allows you to continue the pretraining on an Amazon Titan base model using large amounts of unlabeled data. This type of training will adapt the model from a general domain corpus to a more specific domain corpus such as medical, law, finance, and so on, while still preserving most of the capabilities of the Amazon Titan base model.\n",
      "\n",
      "Why should I use continued pretraining in Amazon Bedrock?\n",
      "\n",
      "Enterprises may want to build models for tasks in a specific domain. The base models may not be trained on the technical jargon used in that specific domain. Thus, directly fine-tuning the base model requires large amounts of labeled training records and a long training duration to get accurate results. To ease this burden, the customer can instead provide large amounts of unlabeled data for a continued pretraining job. This job will adapt the Amazon Titan base model to the new domain. Then the customer may fine-tune the newly pretrained custom model to downstream tasks, using significantly fewer labeled training records and with a shorter training duration.\n",
      "\n",
      "How does the continued pretraining feature relate to other AWS services?\n",
      "\n",
      "Amazon Bedrock continued pretraining and fine-tuning have very similar requirements. For this reason, we are choosing to create unified APIs that support both continued pretraining and fine-tuning. Unification of the APIs reduces the learning curve and will help customers use standard features such as Amazon EventBridge to track long running jobs, Amazon S3 integration for fetching training data, resource tags, and model encryption.\n",
      "\n",
      "How do I use Continued Pre-training?\n",
      "\n",
      "Continued pretraining helps you adapt the Amazon Titan models to your domain specific data while still preserving the base functionality of the Amazon Titan models. To create a continued pretraining job, navigate to the Amazon Bedrock console and click on \"Custom Models.\" You will navigate to the custom model page that has two tabs: Models and Training jobs. Both tabs provide a “Customize Model” drop-down menu on the right. Select “Continued Pretraining” from the drop-down menu to navigate to “Create Continued Pretraining Job.\" You will provide the source model, name, model encryption, input data, hyper-parameters and output data. Additionally, you can provide tags, along with details about AWS Identity and Access Management (IAM) roles and resource policies for the job.\n",
      "\n",
      "Amazon Titan\n",
      "\n",
      "What are Amazon Titan models?\n",
      "\n",
      "Exclusive to Amazon Bedrock, the Amazon Titan family of models incorporates 25 years of Amazon experience innovating with AI and machine learning across the business. Amazon Titan FMs provide customers with a breadth of high-performing image, multimodal, and text model choices through a fully managed API. Amazon Titan models are created by AWS and pretrained on large datasets, making them powerful, general-purpose models built to support a variety of use cases, while also supporting the responsible use of AI. Use them as is or privately customize them with your own data.\n",
      "\n",
      "Where can I learn more about the data processed to develop and train Amazon Titan FMs?\n",
      "\n",
      "To learn more about data processed to develop and train Amazon Titan FMs, visit Amazon Titan model training and privacy.\n",
      "\n",
      "Retrieval augmented generation (RAG)\n",
      "\n",
      "What types of data formats are accepted by Knowledge Bases for Amazon Bedrock?\n",
      "\n",
      "Supported data formats include .pdf, .txt, .md, .html, .doc and .docx, .csv, .xls, and .xlsx files. Files must be uploaded to Amazon S3. Point to the location of your data in Amazon S3, and Knowledge Bases for Amazon Bedrock takes care of the entire ingestion workflow into your vector database.\n",
      "\n",
      "How does Knowledge Bases for Amazon Bedrock chunk the documents before converting those chunks to embeddings?\n",
      "\n",
      "Knowledge Bases for Amazon Bedrock provides three options to chunk text before converting it to embeddings.\n",
      "\n",
      "1.  Default option: Knowledge Bases for Amazon Bedrock automatically splits your document into chunks each containing 200 tokens, ensuring that a sentence is not broken in the middle. If a document contains less than 200 tokens, then it is not split any further. An overlap of 20% of tokens is maintained between two consecutive chunks.\n",
      "\n",
      "2.  Fixed size chunking: In this option, you can specify the maximum number of tokens per chunk and the overlap percentage between chunks for Knowledge Bases for Amazon Bedrock, so your document will be automatically split into chunks, ensuring that a sentence is not broken in the middle.\n",
      "\n",
      "3.  Create one embedding per document option: Amazon Bedrock creates one embedding per document. This option is suitable if you have preprocessed your documents by splitting them into separate files and do not want Amazon Bedrock to further chunk your documents.\n",
      "\n",
      "Which embeddings model is used to convert documents into embeddings (vectors)?\n",
      "\n",
      "At present, Knowledge Bases for Amazon Bedrock uses the latest version of the Amazon Titan Text Embeddings model available in Amazon Bedrock. The Amazon Titan Text Embeddings model supports 8K tokens and 25+ languages and creates embeddings of 1,536 dimension size.\n",
      "\n",
      "Which vector databases are supported by Knowledge Bases for Amazon Bedrock?\n",
      "\n",
      "Knowledge Bases for Amazon Bedrock takes care of the entire ingestion workflow of converting your documents into embeddings (vector) and storing the embeddings in a specialized vector database. Knowledge Bases for Amazon Bedrock supports popular databases for vector storage, including vector engine for Amazon OpenSearch Serverless, Pinecone, Redis Enterprise Cloud, Amazon Aurora (coming soon), and MongoDB (coming soon). If you do not have an existing vector database, Amazon Bedrock creates an OpenSearch Serverless vector store for you.\n",
      "\n",
      "Is it possible to do a periodic or event-driven sync from Amazon S3 to Knowledge Bases for Amazon Bedrock?\n",
      "\n",
      "Depending on your use case, you can use Amazon EventBridge to create a periodic or event-driven sync between Amazon S3 and Knowledge Bases for Amazon Bedrock.\n",
      "\n",
      "Model evaluation\n",
      "\n",
      "What is Model Evaluation on Amazon Bedrock?\n",
      "\n",
      "Model Evaluation on Amazon Bedrock allows you to evaluate, compare, and select the best FM for your use case in just a few short steps. Amazon Bedrock offers a choice of automatic evaluation and human evaluation. You can use automatic evaluation with predefined metrics such as accuracy, robustness, and toxicity. You can use human evaluation workflows for subjective or custom metrics such as friendliness, style, and alignment to brand voice. For human evaluation, you can use your in-house employees or an AWS-managed team as reviewers. Model Evaluation on Amazon Bedrock provides built-in curated datasets or you can bring your own datasets.\n",
      "\n",
      "Against what metrics can I evaluate FMs?\n",
      "\n",
      "You can evaluate variety of predefined metrics such as accuracy, robustness, and toxicity using automatic evaluations. You can also use human evaluation workflows for subjective or custom metrics, such as friendliness, relevance, style, and alignment to brand voice.\n",
      "\n",
      "What is the difference between human-based and automatic evaluations?\n",
      "\n",
      "Automatic evaluations allow you to quickly narrow down the list of available FMs against standard criteria (such as accuracy, toxicity and robustness). Human-based evaluations are often used to evaluate more nuanced or subjective criteria that require human judgment and where automatic evaluations might not exist (such as brand voice, creative intent, friendliness).\n",
      "\n",
      "How does automatic evaluation work?\n",
      "\n",
      "You can quickly evaluate Amazon Bedrock models for metrics such as accuracy, robustness, and toxicity by using curated built-in data sets or by bringing your own prompt datasets. After your prompt datasets are sent to Amazon Bedrock models for inference, the model responses are scored with evaluation algorithms for each dimension. The backend engine aggregates individual prompt response scores into summary scores and presents them through easy-to-understand visual reports.\n",
      "\n",
      "How does human evaluation work?\n",
      "\n",
      "Amazon Bedrock allows you to set up human review workflows in a few short steps and bring your in-house employees, or use an expert team managed by AWS, to evaluate models. Through Amazon Bedrock’s intuitive interface, humans can review and give feedback on model responses by clicking thumbs up or down, rating on a scale of 1-5, choosing the best of multiple responses, or ranking prompts. For example, a team member can be shown how two models respond to the same prompt, and then be asked to select the model that shows more accurate, relevant, or stylistic outputs. You can specify the evaluation criteria that matter to you by customizing the instructions and buttons to appear on the evaluation UI for your team. You can also provide detailed instructions with examples and the overall goal of model evaluation, so users can align their work accordingly. This method is useful to evaluate subjective criteria that require human judgement or more nuanced subject matter expertise and that cannot be easily judged by automatic evaluations.\n",
      "\n",
      "Responsible AI\n",
      "\n",
      "What are Guardrails for Amazon Bedrock?\n",
      "\n",
      "Guardrails for Amazon Bedrock help you implement safeguards for your generative AI applications based on your use cases and responsible AI policies. Guardrails helps control the interaction between users and FMs by filtering undesirable and harmful content and will soon redact personally identifiable information (PII), enhancing content safety and privacy in generative AI applications. You can create multiple guardrails with different configurations tailored to specific use cases. Additionally, with the guardrails you can continually monitor and analyze user inputs and FM responses that might violate customer-defined policies.\n",
      "\n",
      "What are the safeguards available in Guardrails for Amazon Bedrock?\n",
      "\n",
      "Guardrails allows you to define a set of policies to help safeguard your generative AI applications. You can configure the following policies in a guardrail.\n",
      "\n",
      "Denied topics: define a set of topics that are undesirable in the context of your application. For example, an online banking assistant can be designed to refrain from providing investment advice.\n",
      "\n",
      "Content filters: configure thresholds to filter harmful content across hate, insults, sexual, and violence categories.\n",
      "\n",
      "Word filters (coming soon): define a set of words to block in user inputs and FM–generated responses.\n",
      "\n",
      "PII redaction (coming soon): select a set of PII that can be redacted in FM–generated responses. Based on the use case, you can also block a user input if it contains PII.\n",
      "\n",
      "Can I use guardrails with all available FMs and tools on Amazon Bedrock?\n",
      "\n",
      "Guardrails can be used with all large language models available on Amazon Bedrock, including Titan, Anthropic Claude, Meta Llama 2, AI21 Jurassic and Cohere Command FMs. It can also be used with fine-tuned FMs as well as Agents for Amazon Bedrock.\n",
      "\n",
      "Does AWS offer an intellectual property indemnity covering copyright claims for its generative AI services?\n",
      "\n",
      "AWS offers an uncapped intellectual property (IP) indemnity for copyright claims arising from generative output of the following generally available Amazon generative AI services: Amazon Titan models, Amazon CodeWhisperer Professional, and other services listed in Section 50.10 of the Service Terms (the “Indemnified Generative AI Services”). This means that customers are protected from third-party claims alleging copyright infringement by the output generated by the Indemnified Generative AI Services in response to inputs or other data provided by the customer. Customers must also use the services responsibly, such as not inputting infringing data or disabling a service’s filtering features.\n",
      "\n",
      "In addition, our standard IP indemnity for use of the services protects customers from third-party claims alleging IP infringement (including copyright claims) by the services and the data used to train them.\n",
      "\n",
      "How to get started \n",
      "              \n",
      "              \n",
      "             \n",
      "            \n",
      "           \n",
      "          \n",
      "          \n",
      "           \n",
      "            \n",
      "             \n",
      "              \n",
      "               \n",
      "               Video \n",
      "               \n",
      "               \n",
      "               Get started with a step-by-step tutorial \n",
      "                \n",
      "                Watch the video \n",
      "                 \n",
      "                   \n",
      "                    \n",
      "                   \n",
      "                \n",
      "               \n",
      "              \n",
      "             \n",
      "           \n",
      "           \n",
      "            \n",
      "             \n",
      "              \n",
      "               \n",
      "               Tutorial \n",
      "               \n",
      "               \n",
      "               Explore common generative AI use cases with Amazon Bedrock Workshop \n",
      "                \n",
      "                Gain hands-on experience\n",
      "{'source': 'https://aws.amazon.com/bedrock/faqs/'}\n",
      "Generative AI›\n",
      "\n",
      "Amazon Bedrock›\n",
      "\n",
      "Agents\n",
      "\n",
      "Agents for Amazon Bedrock\n",
      "\n",
      "Enable generative AI applications to execute multistep tasks across company systems and data sources\n",
      "\n",
      "Agents for Amazon Bedrock demo\n",
      "\n",
      "Agents for Amazon Bedrock enhance operational efficiency, customer service, and decision-making while reducing costs and facilitating innovation.\n",
      "\n",
      "Automatic prompt creation\n",
      "\n",
      "Agents for Amazon Bedrock creates a prompt from the developer-provided instructions (for example, “you are an insurance agent designed to process open claims”), API details needed to complete the tasks, and company data source details from knowledge bases. The automatic prompt creation saves weeks of experimenting with prompts for different FMs.\n",
      "\n",
      "Retrieval augmented generation\n",
      "\n",
      "Agents for Amazon Bedrock securely connects to your company’s data sources, automatically converts data into numerical representations, and augments the user request with the right information to generate an accurate and relevant response. For example, if the user asks about documents required for claims, the agent will look up information from an appropriate knowledge base that you choose (such as the vector engine for Amazon OpenSearch Serverless, Pinecone, or Redis Enterprise Cloud) and provide a response: “You need to turn in your driver’s license, pictures of the damaged car, and an accident report.”\n",
      "\n",
      "Orchestrate and execute multistep tasks\n",
      "\n",
      "Customers can create an agent in Amazon Bedrock in just a few quick steps, accelerating the time it takes to build generative AI capabilities into applications. Customers first select their desired model and write a few instructions in natural language for example, “you are a friendly customer service agent” and “check product availability in the inventory system”). Agents orchestrate and analyze the task and break it down into the correct logical sequence using the FM’s reasoning abilities. Agents automatically call the necessary APIs to transact with the company systems and processes to fulfill the request, determining along the way if they can proceed or if they need to gather more information.\n",
      "\n",
      "Trace through the chain-of-thought reasoning\n",
      "\n",
      "You can step through the agent's reasoning and orchestration plan with the trace capability. With these insights, you can troubleshoot different orchestration issues to steer the model towards the desired behavior for a better user experience. Moreover, you can review the steps and adjust the instructions as you iterate on the application. With complete visibility into the model's reasoning, you can create differentiated applications faster.\n",
      "\n",
      "Prompt engineering\n",
      "\n",
      "Agents for Amazon Bedrock automatically creates a prompt template from the user instructions, action group, and knowledge bases. You can use this template as a baseline to further refine the automatically generated prompt template to enhance the user experience. You can also update the user input, orchestration plan, and the FM response. Lastly, with the ability to modify the prompt template, you can gain better control over the agent orchestration.\n",
      "\n",
      "Return of control\n",
      "\n",
      "Agents for Amazon Bedrock allow you to define an action schema and get the control back whenever the agent invokes the action. This helps you implement business logic in the backend service of your choice. Also, with return of control, you get the ability to execute time-consuming actions in the background (asynchronous execution) while continuing the orchestration flow.\n",
      "\n",
      "How to get started \n",
      "              \n",
      "              \n",
      "             \n",
      "            \n",
      "           \n",
      "          \n",
      "          \n",
      "           \n",
      "            \n",
      "             \n",
      "              \n",
      "               \n",
      "               Guide \n",
      "               \n",
      "               \n",
      "               User Guide: Agents for Amazon Bedrock \n",
      "                \n",
      "                Read the guide \n",
      "                 \n",
      "                   \n",
      "                    \n",
      "                   \n",
      "                \n",
      "               \n",
      "              \n",
      "             \n",
      "           \n",
      "           \n",
      "            \n",
      "             \n",
      "              \n",
      "               \n",
      "               Blog \n",
      "               \n",
      "               \n",
      "               Build generative AI agents with Amazon Bedrock, Amazon DynamoDB, Amazon Kendra, Amazon Lex, and LangChain \n",
      "                \n",
      "                Read the blog \n",
      "                 \n",
      "                   \n",
      "                    \n",
      "                   \n",
      "                \n",
      "               \n",
      "              \n",
      "             \n",
      "           \n",
      "           \n",
      "            \n",
      "             \n",
      "              \n",
      "               \n",
      "               Blog \n",
      "               \n",
      "               \n",
      "               Automate the insurance claim lifecycle using Agents and Knowledge Bases for Amazon Bedrock \n",
      "                \n",
      "                Read the blog \n",
      "                 \n",
      "                   \n",
      "                    \n",
      "                   \n",
      "                \n",
      "               \n",
      "              \n",
      "             \n",
      "           \n",
      "           \n",
      "            \n",
      "             \n",
      "              \n",
      "               \n",
      "               Video \n",
      "               \n",
      "               \n",
      "               Simplify generative AI app development with Agents for Amazon Bedrock \n",
      "                \n",
      "                Watch the video\n",
      "{'source': 'https://aws.amazon.com/bedrock/agents/'}\n",
      "Generative AI›\n",
      "\n",
      "Amazon Bedrock›\n",
      "\n",
      "Developer Experience\n",
      "\n",
      "Amazon Bedrock Developer Experience\n",
      "\n",
      "Amazon Bedrock makes it easy for developers to work with a broad range of high-performing foundation models\n",
      "\n",
      "Choose from leading FMs\n",
      "\n",
      "Amazon Bedrock makes building with a range of foundation models (FMs) as straightforward as an API call. Amazon Bedrock provides access to leading models including AI21 Labs' Jurassic, Anthropic's Claude, Cohere's Command and Embed, Meta's Llama 2, and Stability AI's Stable Diffusion, as well as our own Amazon Titan models. With Amazon Bedrock, you can select the FM that is best suited for your use case and application requirements.\n",
      "\n",
      "Experiment with FMs for different tasks\n",
      "\n",
      "Experiment with different FMs using interactive playgrounds for various modalities including text, chat, and image. The playgrounds allow you to try out various models for your use case to get a feel for the model’s suitability for a given task.\n",
      "\n",
      "Evaluate FMs to select the best one for your use case\n",
      "\n",
      "Model Evaluation on Amazon Bedrock allows you to use automatic and human evaluations to select FMs for a specific use case. Automatic model evaluation uses curated datasets and provides predefined metrics including accuracy, robustness, and toxicity. For subjective metrics, you can use Amazon Bedrock to set up a human evaluation workflow in a few quick steps. With human evaluations, you can bring your own datasets and define custom metrics, such as relevance, style, and alignment to brand voice. Human evaluation workflows can use your own employees as reviewers or you can engage a team managed by AW to perform the human evaluation, where AWS hires skilled evaluators and manages the complete workflow on your behalf. To learn more, read the blog.\n",
      "\n",
      "Privately customize FMs with your data\n",
      "\n",
      "In a few quick steps, Amazon Bedrock lets you go from generic models to ones that are specialized and customized for your business and use case. To adapt an FM for a specific task, you can use a technique called fine-tuning. Point to a few labeled examples in Amazon Simple Storage Service (Amazon S3), and Amazon Bedrock makes a copy of the base model, trains it with your data, and creates a fine-tuned model accessible only to you, so you get customized responses. Fine-tuning is available for Command, Llama 2, Amazon Titan Text Lite and Express, Amazon Titan Image Generator, and Amazon Titan Multimodal Embeddings models. A second way you can adapt Amazon Titan Text Lite and Amazon Titan Express FMs in Amazon Bedrock is with continued pretraining, a technique that uses your unlabeled datasets to customize the FM for your domain or industry. With both fine-tuning and continued pretraining, Amazon Bedrock creates a private, customized copy of the base FM for you, and your data is not used to train the original base models. Your data used to customize models is securely transferred through your Amazon Virtual Private Cloud (Amazon VPC). To learn more, read the blog.\n",
      "\n",
      "Converse API\n",
      "\n",
      "Converse API provides developers a consistent way to invoke Amazon Bedrock models removing the complexity to adjust for model-specific differences such as inference parameters.\n",
      "\n",
      "How to get started \n",
      "              \n",
      "              \n",
      "             \n",
      "            \n",
      "           \n",
      "          \n",
      "          \n",
      "           \n",
      "            \n",
      "             \n",
      "              \n",
      "               \n",
      "               Blog \n",
      "               \n",
      "               \n",
      "               Get started with model customization using Amazon Bedrock \n",
      "                \n",
      "                Read the blog \n",
      "                 \n",
      "                   \n",
      "                    \n",
      "                   \n",
      "                \n",
      "               \n",
      "              \n",
      "             \n",
      "           \n",
      "           \n",
      "            \n",
      "             \n",
      "              \n",
      "               \n",
      "               Blog \n",
      "               \n",
      "               \n",
      "               Learn how to evaluate models for your use case \n",
      "                \n",
      "                Read the blog \n",
      "                 \n",
      "                   \n",
      "                    \n",
      "                   \n",
      "                \n",
      "               \n",
      "              \n",
      "             \n",
      "           \n",
      "           \n",
      "            \n",
      "             \n",
      "              \n",
      "               \n",
      "               Video \n",
      "               \n",
      "               \n",
      "               Accelerate generative AI application development with Amazon Bedrock \n",
      "                \n",
      "                Watch the video\n",
      "{'source': 'https://aws.amazon.com/bedrock/developer-experience/'}\n",
      "Generative AI›\n",
      "\n",
      "Amazon Bedrock›\n",
      "\n",
      "Guardrails\n",
      "\n",
      "Guardrails for Amazon Bedrock\n",
      "\n",
      "Implement safeguards customized to your application requirements and responsible AI policies\n",
      "\n",
      "Build responsible AI applications with Guardrails for Amazon Bedrock\n",
      "\n",
      "See demos on how to create and apply custom-tailored guardrails with foundation models (FMs) to implement responsible AI policies in your generative AI applications.\n",
      "\n",
      "Play\n",
      "\n",
      "Bring a consistent level of AI safety across all your applications\n",
      "\n",
      "Guardrails for Amazon Bedrock evaluates user inputs and FM responses based on use case specific policies, and provides an additional layer of safeguards regardless of the underlying FM. Guardrails can be applied across all large language models (LLMs) on Amazon Bedrock, including fine-tuned models. Customers can create multiple guardrails, each configured with a different combination of controls, and use these guardrails across different applications and use cases. Guardrails can also be integrated with Agents and Knowledge Bases for Amazon Bedrock to build generative AI applications aligned with your responsible AI policies.\n",
      "\n",
      "Block undesirable topics in your generative AI applications\n",
      "\n",
      "Organizations recognize the need to manage interactions within generative AI applications for a relevant and safe user experience. They want to further customize interactions to remain on topics relevant to their business and align with company policies. Using a short natural language description, Guardrails for Amazon Bedrock allows you to define a set of topics to avoid within the context of your application. Guardrails detects and blocks user inputs and FM responses that fall into the restricted topics. For example, a banking assistant can be designed to avoid topics related to investment advice.\n",
      "\n",
      "Filter harmful content based on your responsible AI policies\n",
      "\n",
      "Guardrails for Amazon Bedrock provides content filters with configurable thresholds to filter harmful content across hate, insults, sexual, violence, misconduct (including criminal activity), and prompt attack (prompt injection and jailbreak). Most FMs already provide built-in protections to prevent the generation of harmful responses. In addition to these protections, Guardrails lets you configure thresholds across the different categories to filter out harmful interactions. Increasing the strength of the filter increases the aggressiveness of the filtering. Guardrails automatically evaluate both user queries and FM responses to detect and help prevent content that falls into restricted categories. For example, an ecommerce site can design its online assistant to avoid using inappropriate language, such as hate speech or insults.\n",
      "\n",
      "Redact sensitive information (PII) to protect privacy\n",
      "\n",
      "Guardrails for Amazon Bedrock allows you to detect sensitive content such as personally identifiable information (PII) in user inputs and FM responses. You can select from a list of predefined PII or define custom sensitive information type using regular expressions (RegEx). Based on the use case, you can selectively reject inputs containing sensitive information or redact them in FM responses. For example, you can redact users’ personal information while generating summaries from customer and agent conversation transcripts in a call center.\n",
      "\n",
      "Block inappropriate content with a custom word filter\n",
      "\n",
      "Guardrails for Amazon Bedrock allow you to configure a set of custom words or phrases that you want to detect and block in the interaction between your users and generative AI applications. This will also allow you to detect and block profanity as well as specific custom words such as competitor names or other oﬀensive words.\n",
      "\n",
      "Next steps \n",
      "              \n",
      "              \n",
      "             \n",
      "            \n",
      "           \n",
      "          \n",
      "          \n",
      "           \n",
      "            \n",
      "             \n",
      "              \n",
      "               \n",
      "               Blog \n",
      "               \n",
      "               \n",
      "               Guardrails for Amazon Bedrock now generally available with new safety ﬁlters and privacy controls \n",
      "                \n",
      "                Read the blog \n",
      "                 \n",
      "                   \n",
      "                    \n",
      "                   \n",
      "                \n",
      "               \n",
      "              \n",
      "             \n",
      "           \n",
      "           \n",
      "            \n",
      "             \n",
      "              \n",
      "               \n",
      "               Blog \n",
      "               \n",
      "               \n",
      "               AWS re:Invent 2023 session: Build Responsible AI Applications with Guardrails for Amazon Bedrock \n",
      "                \n",
      "                See the session \n",
      "                 \n",
      "                   \n",
      "                    \n",
      "                   \n",
      "                \n",
      "               \n",
      "              \n",
      "             \n",
      "           \n",
      "           \n",
      "            \n",
      "             \n",
      "              \n",
      "               \n",
      "               Blog \n",
      "               \n",
      "               \n",
      "               Implement safeguards based on your use case and responsible AI principles \n",
      "                \n",
      "                Read the blog \n",
      "                 \n",
      "                   \n",
      "                    \n",
      "                   \n",
      "                \n",
      "               \n",
      "              \n",
      "             \n",
      "           \n",
      "           \n",
      "            \n",
      "             \n",
      "              \n",
      "               \n",
      "               Console \n",
      "               \n",
      "               \n",
      "               Build with Amazon Bedrock today \n",
      "                \n",
      "                Learn more\n",
      "{'source': 'https://aws.amazon.com/bedrock/guardrails/'}\n",
      "Generative AI›\n",
      "\n",
      "Amazon Bedrock›\n",
      "\n",
      "Knowledge Bases\n",
      "\n",
      "Knowledge Bases for Amazon Bedrock\n",
      "\n",
      "With Knowledge Bases for Amazon Bedrock, you can give FMs and agents contextual information from your company’s private data sources for RAG to deliver more relevant, accurate, and customized responses\n",
      "\n",
      "Fully managed support for end-to-end RAG workflow\n",
      "\n",
      "To equip foundation models (FMs) with up-to-date and proprietary information, organizations use Retrieval Augmented Generation (RAG), a technique that fetches data from company data sources and enriches the prompt to provide more relevant and accurate responses. Knowledge Bases for Amazon Bedrock is a fully managed capability that helps you implement the entire RAG workflow from ingestion to retrieval and prompt augmentation without having to build custom integrations to data sources and manage data flows. Alternatively, you can ask questions and summarize data from a single document, without setting up a vector database. You can also have a Session context management is built in, so your app can readily support multi-turn conversations.\n",
      "\n",
      "Securely connect FMs and agents to data sources\n",
      "\n",
      "Point to the location of your data in Amazon Simple Storage Service (Amazon S3), and Knowledge Bases for Amazon Bedrock automatically fetches the documents from multiple sources, divides them into blocks of text, converts the text into embeddings, and stores the embeddings in your vector database. If you do not have an existing vector database, Amazon Bedrock creates an Amazon OpenSearch Serverless vector store for you. Or you can specify an existing vector store in one of the supported databases, including Amazon OpenSearch Serverless, Pinecone, and Redis Enterprise Cloud, with support for Amazon Aurora and MongoDB.\n",
      "\n",
      "Retrieve relevant data and augment prompts\n",
      "\n",
      "You can use the Retrieve API to fetch relevant results for a user query from knowledge bases. The RetrieveAndGenerate API goes one step further by directly using the retrieved results to augment the FM prompt and return the response. You can also add knowledge bases to Agents for Amazon Bedrock to provide contextual information to agents.\n",
      "\n",
      "Provide source attribution\n",
      "\n",
      "All the information retrieved from Knowledge Bases for Amazon Bedrock is provided with citations to improve transparency and minimize hallucinations.\n",
      "\n",
      "How to get started \n",
      "              \n",
      "              \n",
      "             \n",
      "            \n",
      "           \n",
      "          \n",
      "          \n",
      "           \n",
      "            \n",
      "             \n",
      "              \n",
      "               \n",
      "               Blog \n",
      "               \n",
      "               \n",
      "               Implement RAG workflows using Knowledge Bases for Amazon Bedrock \n",
      "                \n",
      "                Read the blog \n",
      "                 \n",
      "                   \n",
      "                    \n",
      "                   \n",
      "                \n",
      "               \n",
      "              \n",
      "             \n",
      "           \n",
      "           \n",
      "            \n",
      "             \n",
      "              \n",
      "               \n",
      "               Tutorial \n",
      "               \n",
      "               \n",
      "               Explore common generative AI use cases with Amazon Bedrock Workshop \n",
      "                \n",
      "                Gain hands-on experience \n",
      "                 \n",
      "                   \n",
      "                    \n",
      "                   \n",
      "                \n",
      "               \n",
      "              \n",
      "             \n",
      "           \n",
      "           \n",
      "            \n",
      "             \n",
      "              \n",
      "               \n",
      "               Video \n",
      "               \n",
      "               \n",
      "               Use RAG to improve responses in generative AI applications \n",
      "                \n",
      "                Watch the video\n",
      "{'source': 'https://aws.amazon.com/bedrock/knowledge-bases/'}\n",
      "Generative AI›\n",
      "\n",
      "Amazon Bedrock›\n",
      "\n",
      "Security and Privacy\n",
      "\n",
      "Amazon Bedrock Security and Privacy\n",
      "\n",
      "Amazon Bedrock helps you keep your data and applications secure and private\n",
      "\n",
      "Secure your generative AI applications\n",
      "\n",
      "With Amazon Bedrock, you have full control over the data you use to customize the foundation models for your generative AI applications. Your data is encrypted in transit and at rest. Additionally, you can create, manage, and control encryption keys using the AWS Key Management Service (AWS KMS). Identity-based policies provide further control over your data, helping you manage what actions users and roles can perform, on which resources, and under what conditions.\n",
      "\n",
      "Build with comprehensive data protection and privacy\n",
      "\n",
      "Amazon Bedrock helps ensure that your data stays under your control. When you tune a foundation model, we base it on a private copy of that model. This means your data is not shared with model providers, and is not used to improve the base models. You can use AWS PrivateLink to establish private connectivity from your Amazon Virtual Private Cloud (VPC) to Amazon Bedrock, without having to expose your VPC to internet traffic. Finally, Bedrock is in scope for common compliance standards including ISO, SOC, CSA STAR Level 2, is HIPAA eligible, and customers can use Bedrock in compliance with the GDPR.\n",
      "\n",
      "Implement governance, and auditability\n",
      "\n",
      "Amazon Bedrock offers comprehensive monitoring and logging capabilities that can support your governance and audit requirements. You can use Amazon CloudWatch to track usage metrics and build customized dashboards with metrics that can be used for your audit purposes. You can also use AWS CloudTrail to monitor API activity and troubleshoot issues as you integrate other systems into your generative AI applications. You can also choose to store the metadata, requests, and responses in your Amazon Simple Storage Service (Amazon S3) bucket, as well as to Amazon CloudWatch Logs. Finally, to prevent potential misuse, Amazon Bedrock implements automated abuse detection mechanisms.\n",
      "\n",
      "How to get started \n",
      "              \n",
      "              \n",
      "             \n",
      "            \n",
      "           \n",
      "          \n",
      "          \n",
      "           \n",
      "            \n",
      "             \n",
      "              \n",
      "               \n",
      "               Video \n",
      "               \n",
      "               \n",
      "               Get started with a step-by-step tutorial \n",
      "                \n",
      "                Watch the video \n",
      "                 \n",
      "                   \n",
      "                    \n",
      "                   \n",
      "                \n",
      "               \n",
      "              \n",
      "             \n",
      "           \n",
      "           \n",
      "            \n",
      "             \n",
      "              \n",
      "               \n",
      "               Tutorial \n",
      "               \n",
      "               \n",
      "               Explore common generative AI use cases with Amazon Bedrock Workshop \n",
      "                \n",
      "                Gain hands-on experience \n",
      "                 \n",
      "                   \n",
      "                    \n",
      "                   \n",
      "                \n",
      "               \n",
      "              \n",
      "             \n",
      "           \n",
      "           \n",
      "            \n",
      "             \n",
      "              \n",
      "               \n",
      "               Video \n",
      "               \n",
      "               \n",
      "               Securely build generative AI apps & control data with Amazon Bedrock\n",
      "{'source': 'https://aws.amazon.com/bedrock/security-compliance/'}\n"
     ]
    }
   ],
   "source": [
    "for item in docs:\n",
    "    print(item.page_content)\n",
    "    print(item.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 200)\n",
    "all_splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "docsearch = FAISS.from_documents(all_splits, embeddings)\n",
    "docsearch.save_local(\"faiss_index\")\n",
    "vectorstore= FAISS.load_local(\"faiss_index\", embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Based on the provided documents, Amazon Bedrock helps keep data and applications secure and private in the following ways:\n",
      "\n",
      "- Data is encrypted in transit and at rest.\n",
      "\n",
      "- Users can manage encryption keys using AWS Key Management Service (AWS KMS). \n",
      "\n",
      "- Identity-based policies provide control over data, managing what actions users can perform on resources.\n",
      "\n",
      "- Data is not used to improve Amazon Bedrock's base models or shared with model providers. \n",
      "\n",
      "- Private connectivity can be established between Amazon Bedrock and Amazon VPC using AWS PrivateLink without exposing traffic to the internet.\n",
      "\n",
      "- Amazon Bedrock complies with security and privacy standards like SOC, ISO, HIPAA, GDPR, and has CSA STAR Level 2 certification.\n",
      "\n",
      "So in summary, encryption, access controls, compliance certifications, and private networking help keep data and applications secure with Amazon Bedrock.\n"
     ]
    }
   ],
   "source": [
    "# LCEL RAG Chain 🔗\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "template = \"\"\"\n",
    "Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# Retrieve and Generate\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"mmr\", # Also test \"similarity\n",
    ")\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "question = \"How does Amazon Bedrock help you keep your data and applications secure and private?\"\n",
    "\n",
    "# Chain Invoke\n",
    "response = chain.invoke(question)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here are a few ways Amazon Bedrock helps keep data and applications secure and private:\n",
      "\n",
      "- Encryption in transit and at rest - Your data is encrypted when moving over the network and when stored in Amazon Bedrock.\n",
      "\n",
      "- AWS Key Management Service - You can create, manage, and control the encryption keys used to protect your data. \n",
      "\n",
      "- Identity policies - These allow you to control what actions different users and roles can perform on resources.\n",
      "\n",
      "- Private connectivity - You can use AWS PrivateLink to establish private connectivity between your VPC and Bedrock without exposing your VPC to the internet.\n",
      "\n",
      "- Compliance standards - Bedrock meets common compliance standards like ISO, SOC, HIPAA eligibility, and can be used in compliance with GDPR.\n",
      "\n",
      "- Data isolation - When you tune a model, it uses a private copy so your data is not shared with model providers or used to improve base models. \n",
      "\n",
      "- Auditability - Bedrock provides capabilities to support security and compliance requirements like data encryption and access controls.\n",
      "\n",
      "So in summary, encryption, identity policies, private networking, compliance certifications, data isolation, and audit trails all help keep your data and applications secure with Amazon Bedrock.\n"
     ]
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "chain = RetrievalQA.from_chain_type(llm=model, retriever=retriever)\n",
    "\n",
    "response = chain.invoke(question)\n",
    "print(response['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://medium.com/@dminhk/langchain-question-answering-with-amazon-bedrock-1e6519735633"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
